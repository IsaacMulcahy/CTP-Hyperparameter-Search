Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-2.227152,1.0836351,9.579013e-05,0.0,0.09422809,0.06770826,0.4061401740412596,4960.111111111111,0.5670049943728372
50000,-5.213546,0.2328207,9.528351e-05,0.0,0.23602995,0.070768416,None,None,-0.8807799415662885
55000,-4.137098,0.24531385,9.4734314e-05,0.0,0.1885731,0.06986459,-1.0999200537116849,992.0,-1.0999199785292149
60000,-4.288019,0.34155792,9.425415e-05,0.0,0.1373084,0.0706588,None,None,None
65000,-3.5379405,0.32149458,9.375951e-05,0.0,0.15637651,0.07546377,-0.8221422685811477,992.0,-0.8221421196228929
