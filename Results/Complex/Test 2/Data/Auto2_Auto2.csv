Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-2.1632879,0.92170155,0.0009579014,0.0,0.26026067,0.06761131,-0.7490844134331888,4960.111111111111,-0.6946350084617734
50000,-12.069705,0.14874707,0.0009528062,0.0,3.233717,0.06651306,None,None,-1.1846800297498703
55000,-9.589046,1.2585257e-08,0.0009475267,0.0,2.4066527,0.06902257,-1.0999200537116849,992.0,-1.0999199785292149
60000,-7.6735926,2.9264049e-08,0.00094252836,0.0,0.856338,0.06780565,None,None,None
65000,-6.208665,2.7613515e-07,0.00093744183,0.0,1.1552433,0.064872764,-1.0999200537116849,992.0,-1.0999199785292149
70000,-4.8465214,6.918952e-06,0.00093240355,0.0,0.33436468,0.07255741,None,None,None
75000,-3.3477597,1.6930057e-05,0.000927331,0.0,0.3365393,0.07090761,-1.0999200537116849,992.0,-1.0999199785292149
80000,-2.9933283,3.3594827e-07,0.00092269364,0.0,0.0849615,0.06352915,None,None,None
