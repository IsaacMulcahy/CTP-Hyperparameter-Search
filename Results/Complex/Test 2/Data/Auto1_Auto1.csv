Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-2.0569723,1.1607114,0.0009579014,0.0,0.008547448,0.063607454,-0.5181221604519427,4960.111111111111,-0.495352505822666
50000,-15.399511,0.1884854,0.0009528134,0.0,6.446524,0.067161106,-0.5809599655040074,201.0,-0.6406200286000967
55000,-13.387602,1.716068e-05,0.00094748713,0.0,3.9644423,0.072914414,-1.097365048314714,966.5,-1.0973649774678051
60000,-13.208011,5.8291593e-05,0.00094250764,0.0,3.064869,0.07274476,None,None,None
65000,-10.924732,0.0002951458,0.0009372769,0.0,2.9184828,0.07201536,-1.0999200537116849,992.0,-1.0999199785292149
70000,-9.6440935,0.00078152725,0.00093240157,0.0,1.6109251,0.068527535,None,None,None
75000,-8.701491,0.000117361546,0.00092738366,0.0,2.163589,0.064823605,-1.089073383166073,1211.2222222222222,-1.0890733150558338
80000,-8.844664,5.5439694e-05,0.0009226724,0.0,0.9101418,0.074022695,None,None,None
