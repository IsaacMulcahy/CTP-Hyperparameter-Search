Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-0.23378775,0.5763329,0.00095712853,0.0,0.010621268,0.066575795,-0.1263797603041894,4960.0,-0.1263800859451294
50000,-0.1786157,0.45303234,0.0009522163,0.0,0.0046652798,0.06843172,None,None,None
55000,-0.25004572,0.077487215,0.000946992,0.0,0.0019047795,0.07597728,2.3371601984632435,4960.8,2.3371598863042893
60000,-0.1165613,0.14458618,0.00094249396,0.0,0.0025050768,0.07409275,None,None,None
65000,-0.21483426,0.20372258,0.0009372121,0.0,0.0065516625,0.07045683,2.815705660323829,3224.125,2.8157051280140877
70000,-0.23350544,0.14057188,0.0009323857,0.0,0.0031995024,0.06362231,None,None,None
75000,-0.23846887,0.10750214,0.0009273571,0.0,0.0031610026,0.061385345,0.18097336318411786,881.8888888888889,0.18097332694257298
80000,-0.11346724,0.13875224,0.0009227001,0.0,0.00033885002,0.07384082,None,None,None
