Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-2.9728394,1.1084129,0.0009579014,0.0,0.27566344,0.072298005,1.037324691686485,4960.111111111111,1.2238947710720822
50000,-4.1972265,0.11436642,0.0009527869,0.0,0.5871481,0.07736638,None,None,-0.4552401853725314
55000,-3.5406265,0.04237079,0.0009475414,0.0,0.21215825,0.07252235,-1.099835602033838,991.1111111111111,-1.099835538615783
60000,-2.4102778,0.19459805,0.0009425703,0.0,0.045403704,0.072079144,None,None,None
65000,-2.015756,0.22999749,0.00093749235,0.0,0.10041417,0.0656011,-1.0999200537116849,992.0,-1.0999199785292149
70000,-1.0744506,0.25518772,0.00093250687,0.0,0.010826764,0.07119393,None,None,None
75000,-0.84263444,0.17116824,0.00092745683,0.0,0.030726839,0.061773457,-1.0999200537116849,992.0,-1.0999199785292149
80000,-0.4305478,0.07439022,0.00092259515,0.0,0.007810002,0.11236164,None,None,None
