Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,1.397662,0.8340443,0.0009579014,0.0,0.09906924,0.06908831,-0.32821548018425045,4960.111111111111,-0.2817075989441946
50000,4.2893,0.09540249,0.00095275074,0.0,0.29163423,0.078771725,None,None,-0.7002800218760967
55000,3.0898023,0.006363493,0.0009475021,0.0,0.2391066,0.07165617,-1.0999200537116849,992.0,-1.0999199785292149
60000,2.3592477,0.013399979,0.00094252377,0.0,0.041908123,0.06578724,None,None,None
65000,1.5533249,0.0076865572,0.00093744294,0.0,0.07908413,0.065933555,-1.0999200537116849,992.0,-1.0999199785292149
70000,1.2184734,5.0190632e-05,0.0009324345,0.0,0.004598995,0.061486762,None,None,None
75000,1.047459,5.027422e-05,0.00092736044,0.0,0.04911371,0.0719648,-1.0999200537116849,992.0,-1.0999199785292149
80000,0.8790065,1.3426525e-05,0.00092261576,0.0,0.0029841803,0.07646782,None,None,None
