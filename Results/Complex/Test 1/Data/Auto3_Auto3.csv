Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-1.7524495,0.8109152,0.0009579014,0.0,0.10340953,0.06775863,0.9203024188769228,4960.111111111111,0.7478749712463468
50000,-4.0402703,0.040216014,0.00095275557,0.0,0.18140289,0.073182225,None,None,2.29971968755126
55000,-4.0235276,0.017329996,0.0009474491,0.0,0.17612155,0.067870945,-1.0442178173988295,990.3333333333334,-1.0442177595363722
60000,-3.0745764,0.033053104,0.0009425688,0.0,0.03988213,0.06606673,None,None,None
65000,-2.733404,0.13521855,0.000937478,0.0,0.082323894,0.0669702,-0.8776978256072552,992.0,-0.8776976975301901
70000,-2.5771823,0.009788677,0.0009324877,0.0,0.027543014,0.074118316,None,None,None
75000,-1.9674805,0.0021888386,0.00092739245,0.0,0.03906532,0.07227401,-0.933253374169807,992.0,-0.9332532994449139
80000,-1.6926059,0.0074724783,0.0009226679,0.0,0.007073161,0.072746955,None,None,None
