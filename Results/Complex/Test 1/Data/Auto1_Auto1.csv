Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-1.5442953,0.33226302,0.0009579014,0.0,0.21002641,0.08290416,-0.18391778178819448,4960.111111111111,-0.4318725161720067
50000,-2.9475396,0.07268721,0.00095277344,0.0,0.21921672,0.06330133,None,None,1.7997200824320316
55000,-1.7331593,5.4156016e-20,0.00094757776,0.0,0.041812774,0.07163582,-1.099802281937122,990.7777777777778,-1.099802226242092
60000,-1.4842987,1.1668596e-17,0.0009425753,0.0,0.023466183,0.06258625,None,None,None
65000,-0.9173835,9.030519e-16,0.0009375026,0.0,0.004829485,0.06523855,-1.0999200537116849,992.0,-1.0999199785292149
70000,-0.7175003,2.853654e-12,0.00093246525,0.0,0.00348967,0.07030176,None,None,None
75000,-0.58428407,7.3270744e-11,0.00092731736,0.0,0.005488189,0.06952636,-1.0999200537116849,992.0,-1.0999199785292149
80000,-0.5141696,4.716514e-17,0.00092265615,0.0,0.0021867314,0.0743678,None,None,None
