Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,6.495697,1.4770106,9.5691365e-05,0.0,0.55380213,0.06399745,8.61505116511762,4960.0,8.615049911662936
50000,5.969717,1.3349718,9.522168e-05,0.0,0.58562255,0.059475712,None,None,None
55000,5.1662655,1.363008,9.4760355e-05,0.0,0.31371903,0.068298474,None,None,None
60000,4.7135553,1.3630843,9.4242336e-05,0.0,0.24516487,0.06515418,None,None,None
65000,3.6024013,1.4175733,9.372544e-05,0.0,0.16063368,0.07834129,3.8000998739371425,1983.0,3.800100300461054
70000,2.913278,1.4091952,9.326395e-05,0.0,0.080237105,0.06930419,None,None,None
75000,1.99702,1.3304415,9.275482e-05,0.0,0.084112234,0.06813095,4.670243310117387,1570.0,4.670243161597422
