Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,0.43116847,1.225425,0.00095711305,0.0,0.010236696,0.07472412,-0.4138777442508904,4964.444444444444,-0.6275901020271704
50000,0.47183198,0.88449043,0.0009526016,0.0,0.10647091,0.07359105,None,None,1.2958198990672827
55000,-0.14437081,0.81799024,0.00094751304,0.0,0.003846229,0.07330224,-1.0994422776477424,987.1111111111111,-1.0994422274331253
60000,0.12027405,0.8639782,0.00094253774,0.0,0.0011146436,0.070332915,None,None,None
65000,-0.07489011,0.83726215,0.00093757396,0.0,0.003985564,0.073447675,-1.0999200537116849,992.0,-1.0999199785292149
70000,0.04530103,0.8188752,0.0009324326,0.0,0.00036703635,0.06835121,None,None,None
75000,0.13223778,0.84284055,0.00092738884,0.0,0.005797037,0.07332963,-1.0443644966855774,992.0,-1.0443644068307347
80000,-0.00013016585,0.90911275,0.00092266756,0.0,0.0007086096,0.06415269,None,None,None
