Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-2.341755,0.7444413,0.0009579014,0.0,0.02409017,0.070863634,-0.8316355319962491,4960.111111111111,-0.848055120666686
50000,-0.20104285,0.2541637,0.000952839,0.0,0.44976103,0.066011,None,None,-0.7002800814807415
55000,1.3547862,8.537972e-12,0.00094751356,0.0,0.63718146,0.06973174,-1.0999200537116849,992.0,-1.0999199785292149
60000,1.4207227,5.859577e-11,0.0009425256,0.0,0.06757017,0.0743506,None,None,None
65000,2.5664027,1.0278604e-09,0.00093759,0.0,1.0286105,0.07300288,-1.0999200537116849,992.0,-1.0999199785292149
70000,4.055963,1.869317e-07,0.0009324887,0.0,0.5496715,0.071381226,None,None,None
75000,2.301377,4.246404e-07,0.0009273169,0.0,1.2965578,0.06818281,-1.0999200537116849,992.0,-1.0999199785292149
80000,2.7043047,4.7175678e-07,0.000922472,0.0,0.32889366,0.06687583,-1.0999200537116849,992.0,None
