Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-0.7511919,0.94619393,9.563511e-05,0.0,0.0077154143,0.0791815,0.7408502295472772,4960.125,0.740850041154772
50000,-0.9777754,0.79682034,9.522392e-05,0.0,0.0180007,0.05442183,None,None,None
55000,-0.28091392,0.81395924,9.4766474e-05,0.0,0.014230601,0.07003797,-0.586966705350076,1543.2222222222222,-0.5869666569762759
60000,-0.4331859,0.73529464,9.425434e-05,0.0,0.002940211,0.0673727,None,None,None
65000,-0.26970303,0.7596991,9.372493e-05,0.0,0.01699316,0.06368815,-0.9124200487485723,992.0,-0.9124199273064733
70000,-0.30029514,0.7892832,9.3239345e-05,0.0,0.0026207352,0.066162646,None,None,None
75000,-0.25708145,0.8890496,9.273321e-05,0.0,0.009276101,0.061774336,-0.9749200504029432,992.0,-0.9749199380166829
80000,-0.3610421,1.0124018,9.22499e-05,0.0,0.0019481505,0.07200962,None,None,None
