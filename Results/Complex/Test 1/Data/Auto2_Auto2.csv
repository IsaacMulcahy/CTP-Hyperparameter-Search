Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,0.7929633,0.80079263,0.0009579014,0.0,0.039103113,0.07948945,-0.23637761640101315,4960.111111111111,-0.11589035100769252
50000,0.7795515,0.09052026,0.00095274084,0.0,0.17181575,0.06565486,None,None,-1.2002800069749355
55000,-0.44957438,0.00035884752,0.000947302,0.0,0.03154516,0.06949903,-1.0999200537116849,992.0,-1.0999199785292149
60000,0.48054647,3.135494e-05,0.0009425551,0.0,0.06799198,0.066952944,None,None,None
65000,-0.28418443,0.00015295763,0.00093762716,0.0,0.02023656,0.073227376,-1.0999200537116849,992.0,-1.0999199785292149
70000,0.17199013,0.00014074963,0.0009324856,0.0,0.028838666,0.06972311,None,None,None
75000,-0.046330392,0.00012675648,0.00092742813,0.0,0.050758574,0.0670512,-1.0999200537116849,992.0,-1.0999199785292149
80000,-0.05638794,0.00019378737,0.0009226865,0.0,0.002927508,0.06321044,None,None,None
