Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-2.0968614,0.6090381,9.5647396e-05,0.0,0.049676046,0.06846224,1.3046303143023579,4960.125,1.3046297314576805
50000,-2.5532644,0.1297264,9.522421e-05,0.0,0.09551456,0.06798271,None,None,None
55000,-2.2371776,0.18915436,9.47437e-05,0.0,0.051831935,0.06530428,-0.5123822676622594,1543.2222222222222,-0.5123821332947247
60000,-1.7201306,0.24013288,9.425618e-05,0.0,0.017152281,0.06964013,None,None,None
65000,-1.2891258,0.27024636,9.375407e-05,0.0,0.028947908,0.05988395,-0.8221422685811477,992.0,-0.8221421130001545
70000,-0.1753331,0.26686993,9.3246825e-05,0.0,0.07988255,0.072752364,None,None,None
