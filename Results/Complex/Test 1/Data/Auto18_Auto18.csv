Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-10.085611,1.047727,9.5649746e-05,0.0,0.96594125,0.061458178,2.160213816848227,4960.166666666667,2.160213229401658
50000,-9.688676,0.79950947,9.521995e-05,0.0,1.6120176,0.06418364,None,None,None
55000,-8.456644,0.7664294,9.474295e-05,0.0,1.0344071,0.07537863,0.6355315699152665,2409.4285714285716,0.6355314715100187
60000,-6.9287577,0.7568199,9.425012e-05,0.0,0.45134556,0.06261937,None,None,None
65000,-6.1441555,0.7630572,9.3754155e-05,0.0,0.5416547,0.072925374,0.004191401487072913,1984.0,0.0041913652260388646
70000,-5.6582756,0.66433114,9.3241026e-05,0.0,0.2574313,0.06795654,None,None,None
75000,-4.3453054,0.65929115,9.272603e-05,0.0,0.39910072,0.0673015,-0.015723150346502734,311.15625,-0.015723116346634924
