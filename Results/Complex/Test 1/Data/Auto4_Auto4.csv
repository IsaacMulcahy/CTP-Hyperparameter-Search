Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Policy/Learning Rate,Environment/Lesson,Losses/Value Loss,Losses/Policy Loss,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
45000,-4.716026,0.43353486,0.0009579014,0.0,0.76703334,0.07728219,0.0006600473675967401,4960.111111111111,0.07196492864750326
50000,-5.829879,0.018327191,0.00095276325,0.0,0.78738195,0.07379919,None,None,-0.5697804614901543
55000,-4.818776,0.012904887,0.0009473804,0.0,0.37666973,0.06584071,-1.044342274457449,991.7777777777778,-1.04434218754371
60000,-3.7216725,0.004115542,0.0009425265,0.0,0.10708648,0.07715178,None,None,None
65000,-3.4708917,0.021084044,0.00093739276,0.0,0.25687253,0.061015807,-0.9749200504029432,992.0,-0.9749199198558927
